{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7144cfa",
   "metadata": {},
   "source": [
    "<h1>üß† Practical 10 ‚Äî Implementing & Understanding <b>Variational Autoencoder (VAE)</b></h1>\n",
    "<hr>\n",
    "\n",
    "<h2>üéØ Objective</h2>\n",
    "<p>\n",
    "To implement and understand the working of a <b>Variational Autoencoder (VAE)</b> ‚Äî a generative model that learns probabilistic latent representations and can generate new data similar to the training samples.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üß© 1. Theory</h2>\n",
    "<p>\n",
    "A <b>Variational Autoencoder (VAE)</b> is a <b>generative deep learning model</b> that can generate new samples resembling the training data (e.g., handwritten digits, faces).  \n",
    "Unlike a standard Autoencoder, which encodes data into a single latent vector, a VAE encodes each input as a <b>distribution</b> characterized by a mean (<b>Œº</b>) and variance (<b>œÉ¬≤</b>).\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>‚öôÔ∏è 2. Structure of a VAE</h2>\n",
    "\n",
    "<table>\n",
    "<tr><th>Component</th><th>Description</th></tr>\n",
    "<tr>\n",
    "<td><b>Encoder (Recognition / Inference Network)</b></td>\n",
    "<td>Maps input <b>x</b> to latent variables <b>z</b>, represented by mean (<b>Œº</b>) and standard deviation (<b>œÉ</b>): <br>\n",
    "q<sub>œÜ</sub>(z|x) = N(Œº(x), œÉ¬≤(x))</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Latent Space</b></td>\n",
    "<td>A lower-dimensional probabilistic space from which <b>z</b> is sampled. Continuous and smooth, enabling interpolation.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Decoder (Generative Network)</b></td>\n",
    "<td>Maps sampled <b>z</b> back to reconstruction <b>·∫ã</b>, approximating original input <b>x</b>.</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üßÆ 3. Mathematical Formulation (HTML version)</h2>\n",
    "\n",
    "<ul>\n",
    "<li><b>Encoder Outputs:</b> Œº = f<sub>Œº</sub>(x), &nbsp; logœÉ¬≤ = f<sub>œÉ</sub>(x)</li>\n",
    "<li><b>Sampling Layer (Reparameterization Trick):</b> z = Œº + œÉ ‚äô Œµ, &nbsp; Œµ ‚àº N(0, I)</li>\n",
    "<li><b>Decoder Output:</b> ·∫ã = g(z)</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üß© 4. Reparameterization Trick</h2>\n",
    "<p>\n",
    "Direct sampling from N(Œº, œÉ¬≤) breaks backpropagation.  \n",
    "To make it differentiable, we reparameterize:\n",
    "</p>\n",
    "<p style=\"margin-left:20px;\">\n",
    "<b>z = Œº + œÉ √ó Œµ</b>, &nbsp; where &nbsp; Œµ ‚àº N(0, I)\n",
    "</p>\n",
    "<p>This ensures gradients can flow through Œº and œÉ during training.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>‚öñÔ∏è 5. VAE Loss Function</h2>\n",
    "\n",
    "<p>The total loss combines two components:</p>\n",
    "\n",
    "<ul>\n",
    "<li><b>Reconstruction Loss:</b> Measures how well the decoder reconstructs input x from ·∫ã.  \n",
    "Usually <b>MSE</b> or <b>Binary Cross-Entropy</b>.</li>\n",
    "<li><b>KL Divergence Loss:</b> Regularizes the latent space so that q<sub>œÜ</sub>(z|x) ‚âà p(z), where p(z) = N(0, I).</li>\n",
    "</ul>\n",
    "\n",
    "<p><b>Total Objective:</b></p>\n",
    "<p style=\"margin-left:20px;\">\n",
    "L<sub>VAE</sub> = L<sub>reconstruction</sub> + Œ≤ √ó D<sub>KL</sub>(q<sub>œÜ</sub>(z|x) || p(z))\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Œ≤ (beta) is a weight used in <b>Œ≤-VAE</b> variants to control the trade-off between reconstruction accuracy and regularization.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üß† 6. Intuitive Understanding</h2>\n",
    "\n",
    "<ul>\n",
    "<li>The <b>KL term</b> encourages a smooth and continuous latent space.</li>\n",
    "<li>The <b>Reconstruction term</b> ensures input features are captured effectively.</li>\n",
    "<li>Together, they enable:\n",
    "  <ul>\n",
    "    <li>Smooth interpolation between inputs</li>\n",
    "    <li>Generation of new, realistic samples</li>\n",
    "    <li>Structured, interpretable latent features</li>\n",
    "  </ul>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üîç 7. Model Architecture Summary</h2>\n",
    "\n",
    "<table>\n",
    "<tr><th>Component</th><th>Purpose</th><th>Activation</th></tr>\n",
    "<tr><td>Encoder Hidden Layers</td><td>Extract nonlinear features</td><td>ReLU / LeakyReLU</td></tr>\n",
    "<tr><td>Encoder Output Layers</td><td>Compute mean (Œº) and log variance (logœÉ¬≤)</td><td>Linear</td></tr>\n",
    "<tr><td>Sampling Layer</td><td>Generate latent vector via reparameterization</td><td>‚Äî</td></tr>\n",
    "<tr><td>Decoder Hidden Layers</td><td>Map z back to reconstruction</td><td>ReLU / LeakyReLU</td></tr>\n",
    "<tr><td>Decoder Output Layer</td><td>Generate reconstructed sample</td><td>Sigmoid (0‚Äì1 data) / Tanh (‚Äì1‚Äì1) / Linear (continuous)</td></tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üß© 8. Simplified VAE Flow</h2>\n",
    "\n",
    "<pre>\n",
    "        Input (x)\n",
    "            ‚Üì\n",
    "     [ Encoder Network ]\n",
    "            ‚Üì\n",
    "      Œº(x), œÉ(x)\n",
    "            ‚Üì\n",
    "     z = Œº + œÉ * Œµ\n",
    "            ‚Üì\n",
    "     [ Decoder Network ]\n",
    "            ‚Üì\n",
    "     Reconstructed Output (·∫ã)\n",
    "</pre>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üß∞ 9. Difference: Autoencoder vs. Variational Autoencoder</h2>\n",
    "\n",
    "<table>\n",
    "<tr><th>Aspect</th><th>Autoencoder</th><th>Variational Autoencoder (VAE)</th></tr>\n",
    "<tr><td>Latent Representation</td><td>Deterministic vector</td><td>Probabilistic (Œº, œÉ¬≤)</td></tr>\n",
    "<tr><td>Sampling</td><td>No sampling</td><td>Uses reparameterization</td></tr>\n",
    "<tr><td>Regularization</td><td>None</td><td>KL divergence</td></tr>\n",
    "<tr><td>Generative Ability</td><td>Cannot generate new data</td><td>Can generate new samples</td></tr>\n",
    "<tr><td>Loss Function</td><td>Reconstruction only</td><td>Reconstruction + KL Divergence</td></tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üìä 10. Advantages</h2>\n",
    "<ul>\n",
    "<li>‚úÖ Learns a continuous latent space</li>\n",
    "<li>‚úÖ Can generate new data</li>\n",
    "<li>‚úÖ Enables interpolation and anomaly detection</li>\n",
    "<li>‚úÖ Stable training (compared to GANs)</li>\n",
    "</ul>\n",
    "\n",
    "<h2>‚ö†Ô∏è 11. Disadvantages</h2>\n",
    "<ul>\n",
    "<li>‚ö†Ô∏è Blurry outputs due to Gaussian assumptions</li>\n",
    "<li>‚ö†Ô∏è May underfit complex datasets</li>\n",
    "<li>‚ö†Ô∏è Requires careful Œ≤ balancing</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üß™ 12. Common Applications</h2>\n",
    "\n",
    "<table>\n",
    "<tr><th>Domain</th><th>Example</th></tr>\n",
    "<tr><td>Image Generation</td><td>Generate digits (MNIST), faces (CelebA)</td></tr>\n",
    "<tr><td>Anomaly Detection</td><td>Detect deviations from learned patterns</td></tr>\n",
    "<tr><td>Data Compression</td><td>Compress high-dimensional inputs</td></tr>\n",
    "<tr><td>Semi-supervised Learning</td><td>Leverage latent structure for classification</td></tr>\n",
    "<tr><td>Representation Learning</td><td>Extract meaningful low-dimensional features</td></tr>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üßæ 13. Implementation Notes</h2>\n",
    "\n",
    "<p>If your <b>Basic Autoencoder</b> uses:</p>\n",
    "\n",
    "<pre>\n",
    "encoder: Linear + ReLU\n",
    "decoder: Linear + Sigmoid\n",
    "</pre>\n",
    "\n",
    "<p>Then your <b>VAE</b> should use:</p>\n",
    "\n",
    "<pre>\n",
    "# Encoder\n",
    "encoder_hidden: ReLU\n",
    "encoder_output (Œº, logœÉ¬≤): Linear\n",
    "\n",
    "# Sampling (Reparameterization)\n",
    "z = Œº + œÉ * Œµ\n",
    "\n",
    "# Decoder\n",
    "decoder_hidden: ReLU\n",
    "decoder_output: Sigmoid (for normalized data)\n",
    "</pre>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>üìö References</h2>\n",
    "<ol>\n",
    "<li>Kingma, D.P. & Welling, M. (2014). <i>Auto-Encoding Variational Bayes</i>.</li>\n",
    "<li>Doersch, C. (2016). <i>Tutorial on Variational Autoencoders</i>.</li>\n",
    "<li>Goodfellow et al. (2016). <i>Deep Learning</i> ‚Äî MIT Press.</li>\n",
    "</ol>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>‚úÖ Summary</h2>\n",
    "<p>\n",
    "A <b>Variational Autoencoder</b> merges deep learning with probabilistic modeling to learn a <b>structured, continuous latent space</b> that supports both <b>generation</b> and <b>representation learning</b>.  \n",
    "It forms the basis for modern generative AI systems.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9763582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dimensionality reduction imports\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# VAE sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "latent_dim = 1000  # 2D latent space\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "# Decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "# VAE model definition\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            ) * 28 * 28\n",
    "            kl_loss = -0.5 * tf.reduce_sum(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "            )\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "# Prepare and normalize MNIST\n",
    "(x_train, _), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=50, batch_size=128, verbose=0)\n",
    "\n",
    "# Get latent vectors (means) for test set\n",
    "z_mean, _, _ = encoder.predict(x_test, batch_size=128, verbose=0)\n",
    "\n",
    "# For scalability, sample 2000 points\n",
    "n_samples = 2000\n",
    "indices = np.random.choice(len(z_mean), size=n_samples, replace=False)\n",
    "z_subset = z_mean[indices]\n",
    "y_subset = y_test[indices]\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "z_pca = pca.fit_transform(z_subset)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "z_tsne = tsne.fit_transform(z_subset)\n",
    "\n",
    "# Apply UMAP\n",
    "z_umap = umap.UMAP(n_components=2, random_state=42).fit_transform(z_subset)\n",
    "\n",
    "# Plot all three projections for comparison\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "methods = [('PCA', z_pca), ('t-SNE', z_tsne), ('UMAP', z_umap)]\n",
    "for i, (name, z_vis) in enumerate(methods):\n",
    "    sc = axs[i].scatter(z_vis[:,0], z_vis[:,1], c=y_subset, cmap='tab10', s=7, alpha=0.7)\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].set_xlabel(\"Dim 1\")\n",
    "    axs[i].set_ylabel(\"Dim 2\")\n",
    "fig.colorbar(sc, ax=axs, ticks=range(10))\n",
    "plt.suptitle(\"MNIST VAE 2D Latent Space: PCA vs t-SNE vs UMAP\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Display original and reconstructed images\n",
    "n = 10 # Number of images to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    reconstructed_img = vae.predict(x_test[i].reshape(1, 28, 28, 1))\n",
    "    plt.imshow(reconstructed_img.reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.suptitle(\"Original vs. Reconstructed Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dimensionality reduction imports\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# -------------------------\n",
    "# VAE Sampling layer\n",
    "# -------------------------\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# -------------------------\n",
    "# Model hyperparams\n",
    "# -------------------------\n",
    "latent_dim = 2  # note: set >1 for richer latent representations\n",
    "\n",
    "# -------------------------\n",
    "# Encoder\n",
    "# -------------------------\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "# -------------------------\n",
    "# Decoder\n",
    "# -------------------------\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "# -------------------------\n",
    "# VAE model definition\n",
    "# -------------------------\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        # --- metrics to track (Keras will reset them each epoch) ---\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "        # Validation metrics (optional separate trackers)\n",
    "        self.val_total_loss_tracker = keras.metrics.Mean(name=\"val_loss\")\n",
    "        self.val_reconstruction_loss_tracker = keras.metrics.Mean(name=\"val_reconstruction_loss\")\n",
    "        self.val_kl_loss_tracker = keras.metrics.Mean(name=\"val_kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Keras uses this list to reset metrics at the start of each epoch.\n",
    "        # Include both train and val trackers so fit() can show/record them.\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.val_total_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "            self.val_kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def compute_losses(self, data, training=False):\n",
    "        \"\"\"Return (total_loss, reconstruction_loss, kl_loss) for a batch.\"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder(data, training=training)\n",
    "        reconstruction = self.decoder(z, training=training)\n",
    "        # Binary crossentropy returns per-pixel loss (shape: batch, 28*28)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            keras.losses.binary_crossentropy(data, reconstruction)\n",
    "        ) * 28 * 28\n",
    "        kl_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "        )\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]  # unsupervised, so ignore labels if any\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.compute_losses(data, training=True)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        # update training metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        # return dict of metric name -> value (Keras uses this for History)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \"\"\"Called during validation: compute losses and update val metrics.\"\"\"\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        total_loss, reconstruction_loss, kl_loss = self.compute_losses(data, training=False)\n",
    "\n",
    "        # Update validation metrics trackers\n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.val_kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.val_total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.val_reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.val_kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "# -------------------------\n",
    "# Prepare and normalize MNIST\n",
    "# -------------------------\n",
    "(x_train, _), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
    "\n",
    "# -------------------------\n",
    "# Training helper + plotting\n",
    "# -------------------------\n",
    "def smooth_array(x, window_len=5):\n",
    "    \"\"\"Simple moving-average smoothing. Returns original if window_len<=1 or too short.\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    if window_len is None or window_len <= 1 or x.size < window_len:\n",
    "        return x\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-2:-window_len-1:-1]]\n",
    "    w = np.ones(window_len)/window_len\n",
    "    y = np.convolve(w, s, mode='valid')\n",
    "    # align trimmed edges back to original length\n",
    "    trim = (window_len // 2)\n",
    "    return y[trim: trim + x.size]\n",
    "\n",
    "def train_vae_and_plot(vae, x_train, epochs=50, batch_size=128,\n",
    "                       validation_data=None, callbacks=None,\n",
    "                       verbose=0, smooth_window=None, **fit_kwargs):\n",
    "    \"\"\"\n",
    "    Trains the VAE (using model.fit) and plots loss curves.\n",
    "    - smooth_window: int or None. If int>1, plot moving-average-smoothed curves too.\n",
    "    Returns: history (keras History)\n",
    "    \"\"\"\n",
    "    history = vae.fit(\n",
    "        x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "        **fit_kwargs\n",
    "    )\n",
    "\n",
    "    hist = history.history\n",
    "    steps = range(1, len(hist[\"loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    # raw curves\n",
    "    plt.plot(steps, hist[\"loss\"], label=\"Train Total Loss\", alpha=0.6)\n",
    "    if \"reconstruction_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"reconstruction_loss\"], label=\"Train Reconstruction\", alpha=0.6)\n",
    "    if \"kl_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"kl_loss\"], label=\"Train KL\", alpha=0.6)\n",
    "\n",
    "    if \"val_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"val_loss\"], label=\"Val Total Loss\", alpha=0.9)\n",
    "    if \"val_reconstruction_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"val_reconstruction_loss\"], label=\"Val Reconstruction\", alpha=0.9)\n",
    "    if \"val_kl_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"val_kl_loss\"], label=\"Val KL\", alpha=0.9)\n",
    "\n",
    "    # optional smoothed curves\n",
    "    if smooth_window is not None and isinstance(smooth_window, int) and smooth_window > 1:\n",
    "        try:\n",
    "            sm_loss = smooth_array(np.array(hist[\"loss\"]), window_len=smooth_window)\n",
    "            plt.plot(steps, sm_loss, linestyle=\"--\", label=f\"Smoothed Train Total (w={smooth_window})\")\n",
    "            if \"val_loss\" in hist:\n",
    "                sm_val = smooth_array(np.array(hist[\"val_loss\"]), window_len=smooth_window)\n",
    "                plt.plot(steps, sm_val, linestyle=\"--\", label=f\"Smoothed Val Total (w={smooth_window})\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"VAE Training & Validation Losses\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.show()\n",
    "\n",
    "    return history\n",
    "\n",
    "# -------------------------\n",
    "# Instantiate, compile and train\n",
    "# -------------------------\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adamax(learning_rate=1e-3))\n",
    "# -------------------------\n",
    "# Callbacks: EarlyStopping + ReduceLROnPlateau\n",
    "# -------------------------\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         # monitor validation total loss\n",
    "    patience=6,                 # number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True,  # restore model weights from the epoch with best monitored value\n",
    "    min_delta=1e-4,             # minimum change to qualify as improvement\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train and plot (this returns the History object)\n",
    "#history = train_vae_and_plot(vae, x_train, epochs=50, batch_size=128, verbose=0)\n",
    "history = train_vae_and_plot(\n",
    "    vae,\n",
    "    x_train,\n",
    "    epochs=100,             # higher max epochs; early stopping will stop earlier if no improvement\n",
    "    batch_size=128,\n",
    "    validation_data=x_test, # validation inputs (no labels needed)\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=0,\n",
    "    smooth_window=7\n",
    ")\n",
    "print(\"Training ran for epochs:\", len(history.history['loss']))\n",
    "# -------------------------\n",
    "# Visualize latent projections (PCA, t-SNE, UMAP)\n",
    "# -------------------------\n",
    "# Get latent vectors (means) for test set\n",
    "z_mean, _, _ = encoder.predict(x_test, batch_size=128, verbose=0)\n",
    "\n",
    "# For scalability, sample 2000 points\n",
    "n_samples = 2000\n",
    "indices = np.random.choice(len(z_mean), size=n_samples, replace=False)\n",
    "z_subset = z_mean[indices]\n",
    "y_subset = y_test[indices]\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "z_pca = pca.fit_transform(z_subset)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, max_iter=1000, random_state=42)\n",
    "z_tsne = tsne.fit_transform(z_subset)\n",
    "\n",
    "# Apply UMAP\n",
    "z_umap = umap.UMAP(n_components=2, random_state=42).fit_transform(z_subset)\n",
    "\n",
    "# Plot all three projections for comparison\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "methods = [('PCA', z_pca), ('t-SNE', z_tsne), ('UMAP', z_umap)]\n",
    "for i, (name, z_vis) in enumerate(methods):\n",
    "    sc = axs[i].scatter(z_vis[:,0], z_vis[:,1], c=y_subset, cmap='tab10', s=7, alpha=0.7)\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].set_xlabel(\"Dim 1\")\n",
    "    axs[i].set_ylabel(\"Dim 2\")\n",
    "fig.colorbar(sc, ax=axs, ticks=range(10))\n",
    "plt.suptitle(\"MNIST VAE 2D Latent Space: PCA vs t-SNE vs UMAP\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# Display original and reconstructed images\n",
    "# -------------------------\n",
    "n = 10 # Number of images to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    reconstructed_img = vae.predict(x_test[i].reshape(1, 28, 28, 1),verbose=0)\n",
    "    plt.imshow(reconstructed_img.reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.suptitle(\"Original vs. Reconstructed Images\")\n",
    "plt.show()\n",
    "# -------------------------\n",
    "# Generate New Images from Random Latent Samples\n",
    "# -------------------------\n",
    "\n",
    "# Number of new images to generate\n",
    "n_images = 20\n",
    "\n",
    "# Sample random latent vectors from standard normal distribution\n",
    "random_latent_vectors = np.random.normal(size=(n_images, latent_dim))\n",
    "\n",
    "# Decode these latent points into new images\n",
    "generated_images = decoder.predict(random_latent_vectors,verbose=0)\n",
    "\n",
    "# Plot the generated images\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n_images):\n",
    "    ax = plt.subplot(2, n_images//2, i + 1)\n",
    "    plt.imshow(generated_images[i].reshape(28, 28), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"New Images Generated by the VAE\")\n",
    "plt.show()\n",
    "# -------------------------\n",
    "# Generate 2D latent space grid\n",
    "# -------------------------\n",
    "grid_size = 15\n",
    "figure = np.zeros((28 * grid_size, 28 * grid_size))\n",
    "# Linearly spaced coordinates corresponding to the quantiles of a normal distribution\n",
    "grid_x = np.linspace(-3, 3, grid_size)\n",
    "grid_y = np.linspace(-3, 3, grid_size)\n",
    "\n",
    "for i, yi in enumerate(grid_y):\n",
    "    for j, xi in enumerate(grid_x):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample, verbose=0)\n",
    "        digit = x_decoded[0].reshape(28, 28)\n",
    "        figure[i * 28: (i + 1) * 28,\n",
    "               j * 28: (j + 1) * 28] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Latent Space Grid: Smooth Interpolation Between Digits\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full flexible VAE notebook cell ‚Äî replace MNIST with your own dataset directory\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Dimensionality reduction (visualization)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# -------------------------\n",
    "# USER CONFIG ‚Äî modify these\n",
    "# -------------------------\n",
    "dataset_path = \"/path/to/your/dataset\"   # <-- set this: directory with subfolders per class OR flat (see note)\n",
    "image_size = (100, 100)                  # desired H, W for model (must be divisible by 2**n_downsamples)\n",
    "channels = 3                             # 1 for grayscale, 3 for RGB\n",
    "batch_size = 64\n",
    "latent_dim = 2                           # set 2 to visualize latent grid; >2 still works for generation\n",
    "n_downsamples = 2                        # number of conv downsample blocks (each halves H,W)\n",
    "base_filters = 32\n",
    "use_mse = True                           # True -> MSE loss and linear decoder (recommended for RGB); False -> BCE + sigmoid\n",
    "epochs = 100\n",
    "validation_split = 0.15                  # fraction of data to hold out for validation\n",
    "seed = 42\n",
    "smooth_window = 7                        # None or int>1 for smoothing plotted curves\n",
    "autotune = tf.data.AUTOTUNE\n",
    "\n",
    "# -------------------------\n",
    "# Helper: smoothing for plots (optional)\n",
    "# -------------------------\n",
    "def smooth_array(x, window_len=5):\n",
    "    x = np.asarray(x)\n",
    "    if window_len is None or window_len <= 1 or x.size < window_len:\n",
    "        return x\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-2:-window_len-1:-1]]\n",
    "    w = np.ones(window_len)/window_len\n",
    "    y = np.convolve(w, s, mode='valid')\n",
    "    trim = (window_len // 2)\n",
    "    return y[trim: trim + x.size]\n",
    "\n",
    "# -------------------------\n",
    "# Data loading: image_dataset_from_directory\n",
    "# - expects dataset_path with subfolders per class. If images are flat, \n",
    "#   put them under a single subfolder or use a custom loader.\n",
    "# -------------------------\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset path not found: {dataset_path}\")\n",
    "\n",
    "# Use two calls to create training and validation splits reproducibly\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    labels=None,                       # unsupervised VAE ‚Äî ignore labels\n",
    "    label_mode=None,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    labels=None,\n",
    "    label_mode=None,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    shuffle=False,\n",
    "    seed=seed,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n",
    "# Normalize to [0,1] float32\n",
    "def normalize_ds(ds):\n",
    "    ds = ds.map(lambda x: tf.cast(x, tf.float32) / 255.0, num_parallel_calls=autotune)\n",
    "    ds = ds.cache().prefetch(autotune)\n",
    "    return ds\n",
    "\n",
    "train_ds = normalize_ds(train_ds)\n",
    "val_ds = normalize_ds(val_ds)\n",
    "\n",
    "# Convert small subset of val to numpy arrays for visualization & encoder.predict later\n",
    "def ds_to_numpy(ds, max_samples=5000):\n",
    "    arr = []\n",
    "    count = 0\n",
    "    for batch in ds:\n",
    "        # batch shape: (B, H, W, C)\n",
    "        b = batch.numpy()\n",
    "        arr.append(b)\n",
    "        count += b.shape[0]\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "    if not arr:\n",
    "        return np.zeros((0, *image_size, channels), dtype=np.float32)\n",
    "    return np.concatenate(arr, axis=0)[:max_samples]\n",
    "\n",
    "x_val_np = ds_to_numpy(val_ds, max_samples=2000)\n",
    "\n",
    "# -------------------------\n",
    "# Sampling layer\n",
    "# -------------------------\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# -------------------------\n",
    "# Dynamic encoder/decoder builder (for arbitrary input shape)\n",
    "# -------------------------\n",
    "def build_conv_vae(input_shape=(100,100,3), latent_dim=2, base_filters=32, n_downsamples=2, use_mse=False):\n",
    "    H, W, C = input_shape\n",
    "    down_factor = 2 ** n_downsamples\n",
    "    if H % down_factor != 0 or W % down_factor != 0:\n",
    "        raise ValueError(f\"image H/W must be divisible by 2**{n_downsamples} = {down_factor}. Got {H}x{W}.\")\n",
    "    # Build encoder\n",
    "    encoder_inputs = keras.Input(shape=input_shape)\n",
    "    x = encoder_inputs\n",
    "    filters = base_filters\n",
    "    for i in range(n_downsamples):\n",
    "        x = layers.Conv2D(filters, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        filters *= 2\n",
    "    conv_h = H // down_factor\n",
    "    conv_w = W // down_factor\n",
    "    filters_last = filters // 2\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    # Build decoder (mirror)\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(conv_h * conv_w * filters_last, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((conv_h, conv_w, filters_last))(x)\n",
    "    filters = filters_last\n",
    "    for i in range(n_downsamples):\n",
    "        # progressively reduce filters back toward base_filters\n",
    "        out_filters = max(base_filters, filters // 2)\n",
    "        x = layers.Conv2DTranspose(out_filters, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        filters = out_filters\n",
    "    # final output\n",
    "    dec_act = \"linear\" if use_mse else \"sigmoid\"\n",
    "    x = layers.Conv2DTranspose(C, 3, padding=\"same\", activation=dec_act)(x)\n",
    "    decoder = keras.Model(latent_inputs, x, name=\"decoder\")\n",
    "\n",
    "    recon_scale = float(H * W * C)  # used to scale BCE or sum MSE\n",
    "    return encoder, decoder, recon_scale\n",
    "\n",
    "# Build models according to user config\n",
    "input_shape = (image_size[0], image_size[1], channels)\n",
    "encoder, decoder, recon_scale = build_conv_vae(\n",
    "    input_shape=input_shape,\n",
    "    latent_dim=latent_dim,\n",
    "    base_filters=base_filters,\n",
    "    n_downsamples=n_downsamples,\n",
    "    use_mse=use_mse\n",
    ")\n",
    "encoder.summary(); decoder.summary()\n",
    "\n",
    "# -------------------------\n",
    "# VAE class with metrics (works with model.fit and callbacks)\n",
    "# -------------------------\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, recon_scale=1.0, use_mse=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.recon_scale = recon_scale\n",
    "        self.use_mse = use_mse\n",
    "\n",
    "        # training metrics\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "        # validation metrics\n",
    "        self.val_total_loss_tracker = keras.metrics.Mean(name=\"val_loss\")\n",
    "        self.val_reconstruction_loss_tracker = keras.metrics.Mean(name=\"val_reconstruction_loss\")\n",
    "        self.val_kl_loss_tracker = keras.metrics.Mean(name=\"val_kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.val_total_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "            self.val_kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def compute_losses(self, data, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(data, training=training)\n",
    "        reconstruction = self.decoder(z, training=training)\n",
    "\n",
    "        if self.use_mse:\n",
    "            # sum MSE per image, then mean over batch\n",
    "            mse_per_image = tf.reduce_sum(tf.math.squared_difference(data, reconstruction), axis=[1,2,3])\n",
    "            reconstruction_loss = tf.reduce_mean(mse_per_image)\n",
    "        else:\n",
    "            # binary_crossentropy returns per-pixel average; scale to sum per image\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            ) * self.recon_scale\n",
    "\n",
    "        kl_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "        )\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.compute_losses(data, training=True)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        total_loss, reconstruction_loss, kl_loss = self.compute_losses(data, training=False)\n",
    "\n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.val_kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.val_total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.val_reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.val_kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        _, _, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# -------------------------\n",
    "# Instantiate, compile, callbacks\n",
    "# -------------------------\n",
    "vae = VAE(encoder, decoder, recon_scale=recon_scale, use_mse=use_mse)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3))\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=8, restore_best_weights=True, min_delta=1e-4, verbose=1\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Train and plot helper\n",
    "# -------------------------\n",
    "def train_vae_and_plot(vae, train_ds, val_ds, epochs=50, smooth_window=None, callbacks=None, verbose=1):\n",
    "    history = vae.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    hist = history.history\n",
    "    steps = range(1, len(hist[\"loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(steps, hist[\"loss\"], label=\"Train Total\", alpha=0.6)\n",
    "    if \"reconstruction_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"reconstruction_loss\"], label=\"Train Recon\", alpha=0.6)\n",
    "    if \"kl_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"kl_loss\"], label=\"Train KL\", alpha=0.6)\n",
    "    if \"val_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"val_loss\"], label=\"Val Total\", alpha=0.9)\n",
    "    if \"val_reconstruction_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"val_reconstruction_loss\"], label=\"Val Recon\", alpha=0.9)\n",
    "    if \"val_kl_loss\" in hist:\n",
    "        plt.plot(steps, hist[\"val_kl_loss\"], label=\"Val KL\", alpha=0.9)\n",
    "\n",
    "    if smooth_window and isinstance(smooth_window, int) and smooth_window > 1:\n",
    "        try:\n",
    "            plt.plot(steps, smooth_array(np.array(hist[\"loss\"]), smooth_window), \"--\", label=f\"Smoothed Train (w={smooth_window})\")\n",
    "            if \"val_loss\" in hist:\n",
    "                plt.plot(steps, smooth_array(np.array(hist[\"val_loss\"]), smooth_window), \"--\", label=f\"Smoothed Val (w={smooth_window})\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Training & Validation Losses\")\n",
    "    plt.legend(); plt.grid(alpha=0.2); plt.show()\n",
    "    return history\n",
    "\n",
    "# Run training\n",
    "history = train_vae_and_plot(vae, train_ds, val_ds, epochs=epochs, smooth_window=smooth_window, callbacks=[early_stop, reduce_lr], verbose=1)\n",
    "\n",
    "# -------------------------\n",
    "# Useful outputs: reconstructions, generation, latent viz (if latent_dim==2)\n",
    "# -------------------------\n",
    "# Get some validation images for quick visualization (use x_val_np)\n",
    "if x_val_np.shape[0] > 0:\n",
    "    n_display = min(10, x_val_np.shape[0])\n",
    "    sample_imgs = x_val_np[:n_display]\n",
    "    # Reconstructions\n",
    "    recon = vae.predict(sample_imgs, verbose=0)\n",
    "    fig = plt.figure(figsize=(2*n_display,4))\n",
    "    for i in range(n_display):\n",
    "        ax = plt.subplot(2, n_display, i+1)\n",
    "        img = sample_imgs[i]\n",
    "        if channels == 1:\n",
    "            plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(np.clip(img, 0, 1))\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(2, n_display, i+1+n_display)\n",
    "        r = recon[i]\n",
    "        if channels == 1:\n",
    "            plt.imshow(r.squeeze(), cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(np.clip(r, 0, 1))\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(\"Original (top) vs Reconstructed (bottom)\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate new images by sampling z ~ N(0,I)\n",
    "n_gen = 12\n",
    "z_rand = np.random.normal(size=(n_gen, latent_dim))\n",
    "generated = decoder.predict(z_rand, verbose=0)\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(n_gen):\n",
    "    ax = plt.subplot(2, n_gen//2, i+1)\n",
    "    img = generated[i]\n",
    "    if channels == 1:\n",
    "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(np.clip(img, 0, 1))\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Generated samples from random z ~ N(0,I)\")\n",
    "plt.show()\n",
    "\n",
    "# If latent_dim == 2: show latent grid\n",
    "if latent_dim == 2:\n",
    "    grid_size = 12\n",
    "    grid_x = np.linspace(-3, 3, grid_size)\n",
    "    grid_y = np.linspace(-3, 3, grid_size)\n",
    "    figure = np.zeros((image_size[0] * grid_size, image_size[1] * grid_size, channels))\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample, verbose=0)[0]\n",
    "            y0 = i * image_size[0]\n",
    "            x0 = j * image_size[1]\n",
    "            figure[y0:y0+image_size[0], x0:x0+image_size[1]] = x_decoded\n",
    "    plt.figure(figsize=(10,10))\n",
    "    if channels == 1:\n",
    "        plt.imshow(figure.squeeze(), cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(np.clip(figure,0,1))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Latent space grid (2D)\")\n",
    "    plt.show()\n",
    "\n",
    "# Latent visualization (PCA, t-SNE, UMAP) using x_val_np if available\n",
    "if x_val_np.shape[0] >= 50:\n",
    "    # get z_mean for validation set via encoder\n",
    "    z_means = []\n",
    "    batch_limit = 2000  # cap to avoid huge compute\n",
    "    count = 0\n",
    "    for batch in val_ds:\n",
    "        b = batch\n",
    "        z_mean, _, _ = encoder.predict(b, verbose=0)\n",
    "        z_means.append(z_mean)\n",
    "        count += z_mean.shape[0]\n",
    "        if count >= batch_limit:\n",
    "            break\n",
    "    if z_means:\n",
    "        z_all = np.concatenate(z_means, axis=0)[:2000]\n",
    "        # If latent_dim > 2, run PCA -> 2D first\n",
    "        if latent_dim > 2:\n",
    "            pca = PCA(n_components=2)\n",
    "            z_2d = pca.fit_transform(z_all)\n",
    "        else:\n",
    "            z_2d = z_all\n",
    "        # t-SNE\n",
    "        try:\n",
    "            z_tsne = TSNE(n_components=2, perplexity=30, random_state=seed).fit_transform(z_2d)\n",
    "        except Exception:\n",
    "            z_tsne = None\n",
    "        # UMAP\n",
    "        try:\n",
    "            z_umap = umap.UMAP(n_components=2, random_state=seed).fit_transform(z_2d)\n",
    "        except Exception:\n",
    "            z_umap = None\n",
    "\n",
    "        plt.figure(figsize=(15,4))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.scatter(z_2d[:,0], z_2d[:,1], s=5, alpha=0.7)\n",
    "        plt.title(\"PCA -> 2D latent\")\n",
    "        if z_tsne is not None:\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.scatter(z_tsne[:,0], z_tsne[:,1], s=5, alpha=0.7)\n",
    "            plt.title(\"t-SNE on latent\")\n",
    "        if z_umap is not None:\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.scatter(z_umap[:,0], z_umap[:,1], s=5, alpha=0.7)\n",
    "            plt.title(\"UMAP on latent\")\n",
    "        plt.suptitle(\"Latent Visualizations\")\n",
    "        plt.show()\n",
    "\n",
    "print(\"Done. Trained epochs:\", len(history.history['loss']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal VAE (memorable exam version) ‚Äî TensorFlow / Keras\n",
    "import numpy as np, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparams\n",
    "latent_dim = 2\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# --- Sampling layer (reparameterization) ---\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mu, logvar = inputs\n",
    "        eps = tf.random.normal(shape=tf.shape(mu))\n",
    "        return mu + tf.exp(0.5 * logvar) * eps\n",
    "\n",
    "# --- Encoder ---\n",
    "inp = keras.Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32,3, strides=2, padding='same', activation='relu')(inp)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "mu = layers.Dense(latent_dim)(x)\n",
    "logvar = layers.Dense(latent_dim)(x)\n",
    "z = Sampling()([mu, logvar])\n",
    "encoder = keras.Model(inp, [mu, logvar, z], name='enc')\n",
    "\n",
    "# --- Decoder ---\n",
    "latent_in = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7*7*32, activation='relu')(latent_in)\n",
    "x = layers.Reshape((7,7,32))(x)\n",
    "x = layers.Conv2DTranspose(32,3, strides=2, padding='same', activation='relu')(x)\n",
    "out = layers.Conv2DTranspose(1,3, padding='same', activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_in, out, name='dec')\n",
    "\n",
    "# --- VAE model with custom train_step (simple) ---\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, enc, dec, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.enc = enc; self.dec = dec\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple): data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            mu, logvar, z = self.enc(data, training=True)\n",
    "            recon = self.dec(z, training=True)\n",
    "            # reconstruction (BCE per-pixel) and KL\n",
    "            recon_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, recon)) * 28 * 28\n",
    "            kl = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar), axis=1))\n",
    "            loss = recon_loss + kl\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\"loss\": loss, \"recon\": recon_loss, \"kl\": kl}\n",
    "    def call(self, inputs):\n",
    "        _,_,z = self.enc(inputs)\n",
    "        return self.dec(z)\n",
    "\n",
    "# --- data (MNIST) ---\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\")/255.\n",
    "x_test  = np.expand_dims(x_test, -1).astype(\"float32\")/255.\n",
    "\n",
    "# --- compile & train ---\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# --- generate some samples ---\n",
    "z_rand = np.random.normal(size=(16, latent_dim))\n",
    "gen = decoder.predict(z_rand)\n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1); plt.imshow(gen[i].squeeze(), cmap='gray'); plt.axis('off')\n",
    "plt.suptitle('Generated samples'); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
